{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Model Training (model own data 1)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 0. Imports"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from keras.models import Sequential\n",
    "from keras.layers import (\n",
    "    Dense,\n",
    "    Dropout,\n",
    "    Flatten,\n",
    "    Conv2D,\n",
    "    BatchNormalization,\n",
    "    Activation,\n",
    "    MaxPooling2D\n",
    ")\n",
    "from keras.preprocessing.image import ImageDataGenerator"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-06-08T14:04:36.621338Z",
     "end_time": "2023-06-08T14:04:39.977428Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 1. Paths"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "# DATASET_BASE_TRAIN_PATH = \"/Users/adamdabkowski/DataspellProjects/Praca_dyplomowa/data/train_resized\"\n",
    "DATASET_BASE_TRAIN_PATH = \"/Users/adamd/DataspellProjects/Facial Expressions Recognition/data/train_resized\"\n",
    "\n",
    "# DATASET_BASE_TRAIN_PATH = \"../new_data\"\n",
    "\n",
    "# DATASET_BASE_TEST_PATH = \"/Users/adamdabkowski/DataspellProjects/Praca_dyplomowa/data/test_resized\"\n",
    "DATASET_BASE_TEST_PATH = \"/Users/adamd/DataspellProjects/Facial Expressions Recognition/data/test_resized\""
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-06-08T14:06:08.298593Z",
     "end_time": "2023-06-08T14:06:08.305288Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 2. Data preprocessing"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 28709 images belonging to 7 classes.\n",
      "Found 7178 images belonging to 7 classes.\n"
     ]
    }
   ],
   "source": [
    "batch_size  = 32\n",
    "img_size = 128\n",
    "\n",
    "datagen_train  = ImageDataGenerator()\n",
    "datagen_val = ImageDataGenerator()\n",
    "\n",
    "train_set = datagen_train.flow_from_directory(\n",
    "    DATASET_BASE_TRAIN_PATH,\n",
    "    target_size = (img_size,img_size),\n",
    "    color_mode = \"grayscale\",\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',\n",
    "    shuffle=True,\n",
    ")\n",
    "\n",
    "test_set = datagen_val.flow_from_directory(\n",
    "    DATASET_BASE_TEST_PATH,\n",
    "    target_size=(img_size,img_size),\n",
    "    color_mode=\"grayscale\",\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',\n",
    "    shuffle=False\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-06-08T14:06:12.829138Z",
     "end_time": "2023-06-08T14:06:13.009438Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 5. Model creating"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "CATEGORIES = [\"angry\", \"disgust\", \"fear\", \"happy\", \"neutral\", \"sad\", \"surprise\"]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-06-08T14:06:21.358802Z",
     "end_time": "2023-06-08T14:06:21.367405Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "from keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    "\n",
    "checkpoint = ModelCheckpoint(\n",
    "    filepath=\"./model_base_data_1.h5\",\n",
    "    monitor='val_loss',\n",
    "    verbose=1,\n",
    "    save_best_only=True,\n",
    "    mode='min'\n",
    ")\n",
    "\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    min_delta=0,\n",
    "    patience=10,\n",
    "    verbose=1,\n",
    "    restore_best_weights=True,\n",
    ")\n",
    "\n",
    "reduce_learning_rate = ReduceLROnPlateau(\n",
    "    monitor='val_loss',\n",
    "    factor=0.2,\n",
    "    patience=5,\n",
    "    verbose=1,\n",
    "    min_delta=0.0001,\n",
    ")\n",
    "\n",
    "callbacks_list = [early_stopping, checkpoint, reduce_learning_rate]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-06-08T14:06:22.501933Z",
     "end_time": "2023-06-08T14:06:22.506101Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "from keras.optimizers import Adam\n",
    "\n",
    "n_classes = len(CATEGORIES)\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(64,(3,3),padding = 'same',input_shape = (img_size,img_size,1)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size = (2,2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(128,(5,5),padding = 'same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size = (2,2)))\n",
    "model.add(Dropout (0.25))\n",
    "\n",
    "model.add(Conv2D(512,(3,3),padding = 'same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size = (2,2)))\n",
    "model.add(Dropout (0.25))\n",
    "\n",
    "model.add(Conv2D(512,(3,3), padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(256))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Dense(512))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Dense(n_classes, activation='softmax'))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-06-08T14:06:33.844245Z",
     "end_time": "2023-06-08T14:06:34.087495Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 128, 128, 64)      640       \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 128, 128, 64)     256       \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " activation (Activation)     (None, 128, 128, 64)      0         \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 64, 64, 64)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 64, 64, 64)        0         \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 64, 64, 128)       204928    \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 64, 64, 128)      512       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " activation_1 (Activation)   (None, 64, 64, 128)       0         \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 32, 32, 128)      0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 32, 32, 128)       0         \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 32, 32, 512)       590336    \n",
      "                                                                 \n",
      " batch_normalization_2 (Batc  (None, 32, 32, 512)      2048      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " activation_2 (Activation)   (None, 32, 32, 512)       0         \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 16, 16, 512)      0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 16, 16, 512)       0         \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 16, 16, 512)       2359808   \n",
      "                                                                 \n",
      " batch_normalization_3 (Batc  (None, 16, 16, 512)      2048      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " activation_3 (Activation)   (None, 16, 16, 512)       0         \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPooling  (None, 8, 8, 512)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 8, 8, 512)         0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 32768)             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 256)               8388864   \n",
      "                                                                 \n",
      " batch_normalization_4 (Batc  (None, 256)              1024      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " activation_4 (Activation)   (None, 256)               0         \n",
      "                                                                 \n",
      " dropout_4 (Dropout)         (None, 256)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 512)               131584    \n",
      "                                                                 \n",
      " batch_normalization_5 (Batc  (None, 512)              2048      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " activation_5 (Activation)   (None, 512)               0         \n",
      "                                                                 \n",
      " dropout_5 (Dropout)         (None, 512)               0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 7)                 3591      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 11,687,687\n",
      "Trainable params: 11,683,719\n",
      "Non-trainable params: 3,968\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer=Adam(learning_rate=0.001),\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "model.summary()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-06-08T14:08:05.068394Z",
     "end_time": "2023-06-08T14:08:05.102749Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 6. Model training"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "epochs = 50"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-06-08T14:08:06.121000Z",
     "end_time": "2023-06-08T14:08:06.134021Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adamd\\AppData\\Local\\Temp\\ipykernel_6552\\2934536250.py:1: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  history = model.fit_generator(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "897/897 [==============================] - ETA: 0s - loss: 1.6906 - accuracy: 0.3524\n",
      "Epoch 1: val_loss improved from inf to 1.99653, saving model to .\\model_base_data_1.h5\n",
      "897/897 [==============================] - 1359s 2s/step - loss: 1.6906 - accuracy: 0.3524 - val_loss: 1.9965 - val_accuracy: 0.2049 - lr: 0.0010\n",
      "Epoch 2/50\n",
      "897/897 [==============================] - ETA: 0s - loss: 1.3447 - accuracy: 0.4817\n",
      "Epoch 2: val_loss improved from 1.99653 to 1.32532, saving model to .\\model_base_data_1.h5\n",
      "897/897 [==============================] - 1348s 2s/step - loss: 1.3447 - accuracy: 0.4817 - val_loss: 1.3253 - val_accuracy: 0.4867 - lr: 0.0010\n",
      "Epoch 3/50\n",
      "897/897 [==============================] - ETA: 0s - loss: 1.2098 - accuracy: 0.5383\n",
      "Epoch 3: val_loss improved from 1.32532 to 1.27875, saving model to .\\model_base_data_1.h5\n",
      "897/897 [==============================] - 1339s 1s/step - loss: 1.2098 - accuracy: 0.5383 - val_loss: 1.2787 - val_accuracy: 0.5080 - lr: 0.0010\n",
      "Epoch 4/50\n",
      "897/897 [==============================] - ETA: 0s - loss: 1.1155 - accuracy: 0.5765\n",
      "Epoch 4: val_loss improved from 1.27875 to 1.23499, saving model to .\\model_base_data_1.h5\n",
      "897/897 [==============================] - 1345s 1s/step - loss: 1.1155 - accuracy: 0.5765 - val_loss: 1.2350 - val_accuracy: 0.5364 - lr: 0.0010\n",
      "Epoch 5/50\n",
      "897/897 [==============================] - ETA: 0s - loss: 1.0281 - accuracy: 0.6115\n",
      "Epoch 5: val_loss improved from 1.23499 to 1.18177, saving model to .\\model_base_data_1.h5\n",
      "897/897 [==============================] - 1341s 1s/step - loss: 1.0281 - accuracy: 0.6115 - val_loss: 1.1818 - val_accuracy: 0.5668 - lr: 0.0010\n",
      "Epoch 6/50\n",
      "897/897 [==============================] - ETA: 0s - loss: 0.9424 - accuracy: 0.6440\n",
      "Epoch 6: val_loss did not improve from 1.18177\n",
      "897/897 [==============================] - 1349s 2s/step - loss: 0.9424 - accuracy: 0.6440 - val_loss: 1.2085 - val_accuracy: 0.5479 - lr: 0.0010\n",
      "Epoch 7/50\n",
      "897/897 [==============================] - ETA: 0s - loss: 0.8412 - accuracy: 0.6867\n",
      "Epoch 7: val_loss did not improve from 1.18177\n",
      "897/897 [==============================] - 1341s 1s/step - loss: 0.8412 - accuracy: 0.6867 - val_loss: 1.3440 - val_accuracy: 0.5159 - lr: 0.0010\n",
      "Epoch 8/50\n",
      "897/897 [==============================] - ETA: 0s - loss: 0.7422 - accuracy: 0.7238\n",
      "Epoch 8: val_loss did not improve from 1.18177\n",
      "897/897 [==============================] - 1346s 2s/step - loss: 0.7422 - accuracy: 0.7238 - val_loss: 1.1869 - val_accuracy: 0.5703 - lr: 0.0010\n",
      "Epoch 9/50\n",
      "897/897 [==============================] - ETA: 0s - loss: 0.6325 - accuracy: 0.7671\n",
      "Epoch 9: val_loss did not improve from 1.18177\n",
      "897/897 [==============================] - 1332s 1s/step - loss: 0.6325 - accuracy: 0.7671 - val_loss: 1.2399 - val_accuracy: 0.5831 - lr: 0.0010\n",
      "Epoch 10/50\n",
      "897/897 [==============================] - ETA: 0s - loss: 0.5377 - accuracy: 0.8012\n",
      "Epoch 10: val_loss did not improve from 1.18177\n",
      "\n",
      "Epoch 10: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n",
      "897/897 [==============================] - 1336s 1s/step - loss: 0.5377 - accuracy: 0.8012 - val_loss: 1.2691 - val_accuracy: 0.5864 - lr: 0.0010\n",
      "Epoch 11/50\n",
      "897/897 [==============================] - ETA: 0s - loss: 0.3482 - accuracy: 0.8789\n",
      "Epoch 11: val_loss did not improve from 1.18177\n",
      "897/897 [==============================] - 1338s 1s/step - loss: 0.3482 - accuracy: 0.8789 - val_loss: 1.2468 - val_accuracy: 0.6218 - lr: 2.0000e-04\n",
      "Epoch 12/50\n",
      "897/897 [==============================] - ETA: 0s - loss: 0.2721 - accuracy: 0.9060\n",
      "Epoch 12: val_loss did not improve from 1.18177\n",
      "897/897 [==============================] - 1352s 2s/step - loss: 0.2721 - accuracy: 0.9060 - val_loss: 1.3291 - val_accuracy: 0.6282 - lr: 2.0000e-04\n",
      "Epoch 13/50\n",
      "897/897 [==============================] - ETA: 0s - loss: 0.2330 - accuracy: 0.9182\n",
      "Epoch 13: val_loss did not improve from 1.18177\n",
      "897/897 [==============================] - 1340s 1s/step - loss: 0.2330 - accuracy: 0.9182 - val_loss: 1.4104 - val_accuracy: 0.6251 - lr: 2.0000e-04\n",
      "Epoch 14/50\n",
      "897/897 [==============================] - ETA: 0s - loss: 0.2087 - accuracy: 0.9272\n",
      "Epoch 14: val_loss did not improve from 1.18177\n",
      "897/897 [==============================] - 1345s 1s/step - loss: 0.2087 - accuracy: 0.9272 - val_loss: 1.4729 - val_accuracy: 0.6237 - lr: 2.0000e-04\n",
      "Epoch 15/50\n",
      "897/897 [==============================] - ETA: 0s - loss: 0.1787 - accuracy: 0.9365Restoring model weights from the end of the best epoch: 5.\n",
      "\n",
      "Epoch 15: val_loss did not improve from 1.18177\n",
      "\n",
      "Epoch 15: ReduceLROnPlateau reducing learning rate to 4.0000001899898055e-05.\n",
      "897/897 [==============================] - 1351s 2s/step - loss: 0.1787 - accuracy: 0.9365 - val_loss: 1.5356 - val_accuracy: 0.6265 - lr: 2.0000e-04\n",
      "Epoch 15: early stopping\n"
     ]
    }
   ],
   "source": [
    "history = model.fit_generator(\n",
    "    generator=train_set,\n",
    "    steps_per_epoch=train_set.n//train_set.batch_size,\n",
    "    epochs=epochs,\n",
    "    validation_data = test_set,\n",
    "    validation_steps = test_set.n//test_set.batch_size,\n",
    "    callbacks=callbacks_list,\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 7. Results"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**7.1 Loss**"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'history' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[4], line 4\u001B[0m\n\u001B[0;32m      2\u001B[0m plt\u001B[38;5;241m.\u001B[39mylabel(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mLoss\u001B[39m\u001B[38;5;124m'\u001B[39m, fontsize\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m16\u001B[39m)\n\u001B[0;32m      3\u001B[0m plt\u001B[38;5;241m.\u001B[39mxlabel(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mEpoch\u001B[39m\u001B[38;5;124m'\u001B[39m, fontsize\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m16\u001B[39m)\n\u001B[1;32m----> 4\u001B[0m plt\u001B[38;5;241m.\u001B[39mplot(\u001B[43mhistory\u001B[49m\u001B[38;5;241m.\u001B[39mhistory[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mloss\u001B[39m\u001B[38;5;124m'\u001B[39m], label\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mTraining Loss\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m      5\u001B[0m plt\u001B[38;5;241m.\u001B[39mplot(history\u001B[38;5;241m.\u001B[39mhistory[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mval_loss\u001B[39m\u001B[38;5;124m'\u001B[39m], label\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mValidation Loss\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m      6\u001B[0m plt\u001B[38;5;241m.\u001B[39mlegend(loc\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mupper right\u001B[39m\u001B[38;5;124m'\u001B[39m)\n",
      "\u001B[1;31mNameError\u001B[0m: name 'history' is not defined"
     ]
    },
    {
     "data": {
      "text/plain": "<Figure size 2000x1000 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(20,10))\n",
    "plt.ylabel('Loss', fontsize=16)\n",
    "plt.xlabel('Epoch', fontsize=16)\n",
    "plt.plot(history.history['loss'], label='Training Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**7.2 Accuracy**"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[2], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m \u001B[43mplt\u001B[49m\u001B[38;5;241m.\u001B[39mfigure(figsize\u001B[38;5;241m=\u001B[39m(\u001B[38;5;241m20\u001B[39m,\u001B[38;5;241m10\u001B[39m))\n\u001B[0;32m      2\u001B[0m plt\u001B[38;5;241m.\u001B[39mylabel(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mAccuracy\u001B[39m\u001B[38;5;124m'\u001B[39m, fontsize\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m16\u001B[39m)\n\u001B[0;32m      3\u001B[0m plt\u001B[38;5;241m.\u001B[39mxlabel(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mEpoch\u001B[39m\u001B[38;5;124m'\u001B[39m, fontsize\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m16\u001B[39m)\n",
      "\u001B[1;31mNameError\u001B[0m: name 'plt' is not defined"
     ]
    }
   ],
   "source": [
    "plt.figure(figsize=(20,10))\n",
    "plt.ylabel('Accuracy', fontsize=16)\n",
    "plt.xlabel('Epoch', fontsize=16)\n",
    "plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
